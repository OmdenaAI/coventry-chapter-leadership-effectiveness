{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "367c19b3",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89963f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import configparser\n",
    "import pandas as pd\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e84fed",
   "metadata": {},
   "source": [
    "## Define useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3fc368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a functions that deals with user filtering and user addition\n",
    "def users_handler(user_info: tweepy.models.User, filters: dict):\n",
    "    \"\"\"\n",
    "    this function is used to filter the given tweepy.models.User instance by performing the following processes:\n",
    "        1- extracting the user bio/description.\n",
    "        2- check if the bio contains at least one of the keywordws present in filters dict.\n",
    "        3- check if the bio does not contains any word of the unwanted keywordws present in filters dict\n",
    "        4- check if the user follwers count are greater than the limit present in filters dict.\n",
    "\n",
    "    \n",
    "    :param: user_info -- an instance of tweepy.models.User class contains the information about collected user.\n",
    "    :param: filters -- a dictionary that contains the filters which the user will be filtered against.\n",
    "    \n",
    "    :return: instance of tweepy.models.User class contains the information about the passed user.\n",
    "        \n",
    "    \"\"\"\n",
    "    # extracting user info \n",
    "    user_bio = user_info.description.lower()\n",
    "    user_follower_count = user_info.followers_count\n",
    "    \n",
    "    if any(word.lower() in user_bio.split() for word in filters['keywords']):\n",
    "        if not any(undesired_word.lower() in user_bio.split() for undesired_word in filters['unwanted keywords']):\n",
    "            if user_follower_count > filters['followers_count']:\n",
    "                return user_info\n",
    "            else:\n",
    "                return -1\n",
    "        else:\n",
    "            return -1            \n",
    "    else:\n",
    "        return -1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c08a937",
   "metadata": {},
   "outputs": [],
   "source": [
    "def users_adder(main_user_dict:dict, user_info: tweepy.models.User):\n",
    "    \"\"\"\n",
    "    this function is used to add the information of the passed user to the df\n",
    "    :param: main_user_dict -- this is the main dictionary that contains the information about the passed users\n",
    "                                {Username:[list of usernames per user], Bio:[list of bio per user],\n",
    "                                profile URL:[list of profile urls per user], Location:[list of locations per user]\n",
    "                                Websites:[list of user website urls]} \n",
    "    :param: user_info -- instance of tweepy.models.User class contains the information about the passed tweet.\n",
    "    \n",
    "    :return: dictionary that contains the passed user info and integer that represent how many user are collected.\n",
    "    \"\"\"\n",
    "\n",
    "    user_name = user_info.screen_name\n",
    "    \n",
    "    user_bio = user_info.description.lower()\n",
    "    \n",
    "    user_url = \"https://twitter.com/{}\".format(tweet.screen_name)\n",
    "    \n",
    "    user_location = user_info.location.lower() \n",
    "    \n",
    "    user_website = user_info.url\n",
    "    \n",
    "    \n",
    "    if not (user_name in main_user_dict['Username']): # cehck to not include duplicate data\n",
    "        \n",
    "        main_user_dict['Username'].append(user_name)\n",
    "        \n",
    "        main_user_dict['Bio'].append(user_bio)\n",
    "        \n",
    "        main_user_dict['profile URL'].append(user_url)\n",
    "        \n",
    "        main_user_dict['Location'].append(user_location)\n",
    "        \n",
    "        main_user_dict['Websites'].append(user_website)\n",
    "    \n",
    "   \n",
    "    return main_user_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44512a3",
   "metadata": {},
   "source": [
    "## Authentication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4b0d51",
   "metadata": {},
   "source": [
    "Before running the below cell you will need to create a config file named config.ini which includes the Twitter API credentials. the structure of the file is like the following:\n",
    "```config\n",
    "\n",
    "[twitter]\n",
    "\n",
    "api_key = \n",
    "api_key_secret = \n",
    "\n",
    "access_token= \n",
    "access_token_secret= \n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4b5916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read config\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "\n",
    "api_key = config['twitter']['api_key']\n",
    "api_key_secret = config['twitter']['api_key_secret']\n",
    "\n",
    "access_token = config['twitter']['access_token']\n",
    "access_token_secret = config['twitter']['access_token_secret']\n",
    "\n",
    "# authentication\n",
    "auth = tweepy.OAuthHandler(api_key, api_key_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061afbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = tweepy.API(auth ,wait_on_rate_limit=True)\n",
    "\n",
    "public_tweets = api.home_timeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffb7dad",
   "metadata": {},
   "source": [
    "## Algorithm description:  \n",
    "\n",
    "the general idea to find the user of interest is: to use the `api.search_users` which is similar to Find People button on Twitter.com; the same results returned by people search on Twitter.com will be returned by using this API.   \n",
    "\n",
    "we will take the following steps:\n",
    "1. create a dictionary that contains:\n",
    "    - words that we want our user's bio to include\n",
    "    - min number of followers of each user\n",
    "    - words that we do not want to include in our search\n",
    "2. generate a combination of 2 words from the previously created keywords\n",
    "3. initialize a main dictionary its keys represents the required info to be collected about the users\n",
    "4. looping on the created combination; and for each combination:\n",
    "    - create the search query\n",
    "    - for each collected user given a combination:\n",
    "        - check if the user passes the specified criteria by utilizing `users_handler()`\n",
    "        - if the user pass, add the collected info to `main_user_dict`\n",
    "        - break from the loop\n",
    "5. create a data frame from the generated dictionary and save the file as CSV  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb36f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the filters up dictionary \n",
    "filters = {'keywords':['CEO', 'vice president', 'president',\n",
    "                      'chief', 'founder', 'co funder', 'CTO', 'Congress Women', 'Congress men',\n",
    "                      'senator', 'MP', 'parliament', 'head', 'senior', 'Activist', 'creator', 'board member',\n",
    "                      'Chairman', 'VP'],\n",
    "           'unwanted keywords': ['sex', 'porn', 'adult', 'PLAYMATE', 'Model'],\n",
    "           'followers_count':10000,}\n",
    "\n",
    "# generating combination of the desired words 2 at a time\n",
    "desired_words_combinations = list(itertools.combinations(filters['keywords'], 2))\n",
    "\n",
    "# setting the unwanted words in tweets\n",
    "undsired_words = ' -'.join(filters['unwanted keywords'])\n",
    "\n",
    "main_user_dict = {'Username':[], 'Bio':[], 'profile URL':[], 'Location':[], 'Websites':[]}\n",
    "\n",
    "for word in desired_words_combinations:\n",
    "    # setting the query\n",
    "    desired_words = ' OR '.join(list(word))\n",
    "    query = '({}) -{} lang:en'.format(desired_words, undsired_words)\n",
    "    print(\"search query is: {} \\n\".format(query))\n",
    "    \n",
    "    tweets = tweepy.Cursor(api.search_users, q=query , count=20, include_entities=True).items(500)\n",
    "    for i, tweet in enumerate(tweets):\n",
    "        responce = users_handler(tweet, filters)\n",
    "        if responce != -1 :\n",
    "            main_user_dict = users_adder(main_user_dict, tweet)    \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0016cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a df from the main_user_dict\n",
    "df = pd.DataFrame(main_user_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0204eb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore df\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e1e65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure there is no duplicate data\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a92fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"Twitter_Users_Info_Africa\"\n",
    "df.to_csv(\"{}.csv\".format(file_name), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Omdena",
   "language": "python",
   "name": "omdena"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
